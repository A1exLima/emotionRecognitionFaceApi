
## üßëüèª‚Äçüíª Reconhecimento facial com React e FastAPi

Reconhecimento facial que capta as express√µes e emo√ß√µes dos seus usu√°rio.
* Acesse: https://emotionrecognitionfaceapi.netlify.app

Neste projeto pr√°tico, foi usado tecnologias como o React com Typescript, Vite, styled-components e a Api FaceApi, que √© uma biblioteca JavaScript de c√≥digo aberto constru√≠da com base no famoso TensorFlow. Nessa aplica√ß√£o, voc√™ poder√° ver em tempo real, por meio de sua webcam, como as express√µes faciais se relacionam com diferentes emo√ß√µes, como felicidade, tristeza, surpresa e raiva.

<img width="400" src="public/page.png"> 
<img width="400" height="254" src="public/example.gif"> 

## üìÑ Tecnologias

As seguintes tecnologias foram empregadas na cria√ß√£o deste projeto:

* [react (v18.3.1)]: Uma biblioteca JavaScript para criar interfaces de usu√°rio, focada na renderiza√ß√£o eficiente e na composi√ß√£o de componentes.
* [react-dom (v18.3.1)]: Fornece m√©todos espec√≠ficos do DOM que s√£o usados ‚Äã‚Äãpela camada de reconcilia√ß√£o do React para renderizar componentes React no DOM.
* [styled-components (v6.1.12)]: Uma biblioteca para escrever estilos em componentes React usando template literals do JavaScript, permitindo estilos din√¢micos e reutiliz√°veis.
* [face-api.js (v0.22.2)]: √â uma biblioteca JavaScript que oferece reconhecimento facial em tempo real, detec√ß√£o de rosto, e an√°lise de express√µes faciais atrav√©s de modelos de aprendizado profundo pr√©-treinados. √â amplamente utilizada para aplica√ß√µes de vis√£o computacional e intera√ß√µes baseadas em reconhecimento facial.
* Link: face-api.js: (<https://justadudewhohacks.github.io/face-api.js/docs/index.html#examples>)

## üî® Requisitos

* Utilize a Media Stream API do browser para habilitar o uso da sua webcam.

#### Existem alguns passos para que a FaceAPI funcione corretamente

* Voc√™ precisar√° carregar os modelos do TensorFlow usando a FaceAPI.
* Os modelos j√° est√£o no reposit√≥rio no caminho /public/models.
* Em seguida, voc√™ ir√° fazer a detec√ß√£o do rosto usando o m√©todo correspondente da FaceAPI.
* Usar o m√©todo da FaceAPI que "desenha" o a captura na tela.
* O desenho ser√° feito em um < canvas > que estar√° sobreposto ao v√≠deo.
* Capturar a express√£o mais prov√°vel da face detectada para que ela seja utilizada no card de resultado da aplica√ß√£o.
* N√£o se esque√ßa que a detec√ß√£o deve ocorrer em tempo real, isto √©, dever√° ocorrer a cada X segundos (ou milissegundos, como preferir).
  
#### Dicas

* Tire as d√∫vidas de uso na documenta√ß√£o Reconhecendo Express√µes;
* Ap√≥s a captura √© necess√°rio desenhar o resultado no canvas;
* Tire as d√∫vidas de uso na documenta√ß√£o Exibindo Resultados;
* Use exemplos da documenta√ß√£o para melhor entendimento sobre a FaceAPI, na documenta√ß√£o tem alguns para melhor entendimento.
* Exiba o nome da express√£o captada pela webcam do usu√°rio acordo com a express√£o: Feliz, Triste, Bravo, Surpreso, Medo ou Enjoado.

## üöÄ Como utilizar

Clone o projeto para o local desejado em seu computador.

```bash
git clone https://github.com/A1exLima/emotionRecognitionFaceApi.git
```

## üöß Executando o front-end

Entre na pasta raiz do reposit√≥rio

```bash
cd emotionRecognitionFaceApi
```

Instale as depend√™ncias necess√°rias

```bash
npm install
```

Execute a aplica√ß√£o localmente:

```bash
npm run dev
```

Clique no link apresentado no terminal segurando ctrl
Exemplo:

```bash
> ts-react-vite-project-template@1.0.0 dev
> vite

  VITE v5.4.0  ready in 768 ms

  ‚ûú  Local:   http://localhost:5173/
  ‚ûú  Network: use --host to expose
  ‚ûú  press h + enter to show help
```

___
<br/>
<p align="center"> created by Alex Lima  - ¬© 2024 - Todos os direitos reservados.<p align="center">
 <a href="https://www.linkedin.com/in/a1exlima/" target="_blank"><img src="https://static.licdn.com/sc/h/5bukxbhy9xsil5mb7c2wulfbx" height="25" width="25" alt="Linked" />
</p></p>

___
